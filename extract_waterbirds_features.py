import sys, types

# --- ğŸ”§ torchvisionì˜ lzma import ìš°íšŒìš© ë”ë¯¸ ëª¨ë“ˆ ìƒì„± ---
if 'lzma' not in sys.modules:
    fake_lzma = types.SimpleNamespace()
    fake_lzma.open = lambda *args, **kwargs: None  # ë”ë¯¸ open í•¨ìˆ˜ ì¶”ê°€
    sys.modules['lzma'] = fake_lzma
# -----------------------------------------------------------

import os
import torch
import numpy as np
from torch.utils.data import DataLoader, Dataset
from torchvision import transforms, models
from PIL import Image
from tqdm import tqdm
import pandas as pd
import torch.nn as nn

# ğŸ”½ config ì¶”ê°€
import utils.config as config

class WaterbirdsDataset(Dataset):
    def __init__(self, data_dir, metadata_path, split, transform=None):
        self.data_dir = data_dir
        self.transform = transform

        self.metadata = pd.read_csv(metadata_path)

        split_dict = {'train': 0, 'val': 1, 'test': 2}
        self.metadata = self.metadata[self.metadata['split'] == split_dict[split]]

        # ğŸ”½ configì—ì„œ target/bias ì»¬ëŸ¼ëª… ë¶ˆëŸ¬ì˜¤ê¸°
        self.target_attr = config.target_attribute
        self.bias_attr = config.bias_attribute

        print(f"ë¡œë“œëœ {split} ì´ë¯¸ì§€ ìˆ˜: {len(self.metadata)}")

    def __len__(self):
        return len(self.metadata)

    def __getitem__(self, idx):
        img_filename = self.metadata.iloc[idx]['img_filename']
        img_path = os.path.join(self.data_dir, img_filename)

        image = Image.open(img_path).convert('RGB')

        if self.transform:
            image = self.transform(image)

        # ğŸ”½ ì»¬ëŸ¼ëª… ê¸°ë°˜ìœ¼ë¡œ targetê³¼ bias ì½ê¸°
        target = int(self.metadata.iloc[idx][self.target_attr])
        bias = int(self.metadata.iloc[idx][self.bias_attr])

        return image, target, bias

def extract_waterbirds_features(data_path, output_path, batch_size=32):
    # ê²½ë¡œ ì„¤ì •
    waterbirds_dir = os.path.join(data_path, "waterbirds")
    waterbirds_dataset_dir = os.path.join(waterbirds_dir, "waterbird_complete95_forest2water2")
    metadata_path = os.path.join(waterbirds_dataset_dir, "metadata.csv")

    os.makedirs(output_path, exist_ok=True)

    # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                             std=[0.229, 0.224, 0.225])
    ])

    # âœ… pretrained ResNet-18 ë¡œë“œ (ë§ˆì§€ë§‰ FC ì œê±°)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    backbone = models.resnet18(pretrained=True)
    backbone.fc = nn.Identity()  # (512-dim features)
    backbone = backbone.to(device)
    backbone.eval()

    for split in ['train', 'val', 'test']:
        print(f"Processing {split} split...")

        dataset = WaterbirdsDataset(waterbirds_dataset_dir, metadata_path, split, transform)
        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=2)

        features_list = []
        targets_list = []
        biases_list = []

        with torch.no_grad():
            for batch_images, batch_targets, batch_biases in tqdm(dataloader):
                batch_images = batch_images.to(device)

                # ì´ë¯¸ì§€ â†’ feature ì¶”ì¶œ
                feats = backbone(batch_images)  # shape: (B, 512)
                feats = feats.view(feats.size(0), -1)

                features_list.append(feats.cpu().numpy())
                targets_list.append(batch_targets.numpy())
                biases_list.append(batch_biases.numpy())

        # ì €ì¥
        all_features = np.concatenate(features_list, axis=0)
        all_targets = np.concatenate(targets_list, axis=0)
        all_biases = np.concatenate(biases_list, axis=0)

        np.save(os.path.join(output_path, f"{split}_feats.npy"), all_features)
        np.save(os.path.join(output_path, f"{split}_targets.npy"), all_targets)
        np.save(os.path.join(output_path, f"{split}_bias.npy"), all_biases)

        print(f"Saved {split} features of shape {all_features.shape}")

if __name__ == "__main__":
    data_path = "./datasets"  # waterbirds í´ë”ê°€ datasets/waterbirdsì— ìˆë‹¤ê³  ê°€ì •
    output_path = "./datasets/waterbirds_features"
    extract_waterbirds_features(data_path, output_path)