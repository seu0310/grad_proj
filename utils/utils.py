import numpy as np
import torch





def _to_numpy(x):
    """torch.Tensor â†’ numpy ë³€í™˜ (ìžë™ ê°ì§€)"""
    if isinstance(x, torch.Tensor):
        return x.detach().cpu().numpy()
    return np.array(x)


def demographic_parity_difference(y_pred, sensitive_attr):
    """
    ðŸ“Š Demographic Parity Difference (DPD)
    ê·¸ë£¹ë³„ ì˜ˆì¸¡ ê¸ì • ë¹„ìœ¨(P(Å¶=1|A))ì˜ ì°¨ì´
    
    y_pred: torch.Tensor or np.array (0/1)
    sensitive_attr: torch.Tensor or np.array (ì˜ˆ: ì„±ë³„, ì¸ì¢… ë“±)
    """
    y_pred = _to_numpy(y_pred)
    sensitive_attr = _to_numpy(sensitive_attr)

    groups = np.unique(sensitive_attr)
    if len(groups) != 2:
        raise ValueError("Demographic ParityëŠ” í˜„ìž¬ ì´ì§„ ê·¸ë£¹ë§Œ ì§€ì›í•©ë‹ˆë‹¤.")

    p_y1_g0 = np.mean(y_pred[sensitive_attr == groups[0]])
    p_y1_g1 = np.mean(y_pred[sensitive_attr == groups[1]])
    dp_diff = abs(p_y1_g0 - p_y1_g1)
    return dp_diff


def equal_opportunity_difference(y_true, y_pred, sensitive_attr):
    """
    ðŸŽ¯ Equal Opportunity Difference (EOD)
    ì‹¤ì œ ê¸ì •(Y=1) ì¤‘ì—ì„œ ì˜ˆì¸¡ë„ ê¸ì •ì¸ ë¹„ìœ¨(TPR)ì˜ ì°¨ì´
    
    y_true: torch.Tensor or np.array (0/1)
    y_pred: torch.Tensor or np.array (0/1)
    sensitive_attr: torch.Tensor or np.array (ì˜ˆ: ì„±ë³„, ì¸ì¢… ë“±)
    """
    y_true = _to_numpy(y_true)
    y_pred = _to_numpy(y_pred)
    sensitive_attr = _to_numpy(sensitive_attr)

    groups = np.unique(sensitive_attr)
    if len(groups) != 2:
        raise ValueError("Equal OpportunityëŠ” í˜„ìž¬ ì´ì§„ ê·¸ë£¹ë§Œ ì§€ì›í•©ë‹ˆë‹¤.")

    # True Positive Rate (TPR)
    tpr_g0 = np.mean(y_pred[(sensitive_attr == groups[0]) & (y_true == 1)])
    tpr_g1 = np.mean(y_pred[(sensitive_attr == groups[1]) & (y_true == 1)])
    eo_diff = abs(tpr_g0 - tpr_g1)
    return eo_diff


def equalized_odds_difference(y_true, y_pred, sensitive_attr):
    """
    âš–ï¸ Equalized Odds Difference (EODs)
    TPR (True Positive Rate)ì™€ FPR (False Positive Rate) ë‘˜ ë‹¤ ë¹„ìŠ·í•´ì•¼ í•¨.
    ë‘ ì§€í‘œì˜ í‰ê·  ì°¨ì´ë¥¼ ë°˜í™˜.
    
    y_true: torch.Tensor or np.array (0/1)
    y_pred: torch.Tensor or np.array (0/1)
    sensitive_attr: torch.Tensor or np.array (ì˜ˆ: ì„±ë³„, ì¸ì¢… ë“±)
    """
    y_true = _to_numpy(y_true)
    y_pred = _to_numpy(y_pred)
    sensitive_attr = _to_numpy(sensitive_attr)

    groups = np.unique(sensitive_attr)
    if len(groups) != 2:
        raise ValueError("Equalized OddsëŠ” í˜„ìž¬ ì´ì§„ ê·¸ë£¹ë§Œ ì§€ì›í•©ë‹ˆë‹¤.")

    # Group 0
    tpr_g0 = np.mean(y_pred[(sensitive_attr == groups[0]) & (y_true == 1)])
    fpr_g0 = np.mean(y_pred[(sensitive_attr == groups[0]) & (y_true == 0)])
    # Group 1
    tpr_g1 = np.mean(y_pred[(sensitive_attr == groups[1]) & (y_true == 1)])
    fpr_g1 = np.mean(y_pred[(sensitive_attr == groups[1]) & (y_true == 0)])

    tpr_diff = abs(tpr_g0 - tpr_g1)
    fpr_diff = abs(fpr_g0 - fpr_g1)
    eod_diff = (tpr_diff + fpr_diff) / 2.0  # í‰ê·  ì°¨ì´
    return eod_diff





def biased_acc(y, y_, u):
    # Computes worst and avg accuracies
    g = np.zeros([2, 2])
    uc = np.zeros([2, 2])
    for i in range(u.shape[0]):
        if u[i] > 0:
            g[int(y[i])][1] += y_[i]
            uc[int(y[i])][1] += 1
        else:
            g[int(y[i])][0] += y_[i]
            uc[int(y[i])][0] += 1
    acc = g / uc
    acc[0, :] = 1 - acc[0, :]
    worst = np.min(acc)
    avg = np.mean(acc)
    #print(acc[0, 0], acc[0, 1], acc[1, 0], acc[1, 1])
    return worst, avg


def save_state_dict(state_dict, save_path):
    # Saves model
    torch.save(state_dict, save_path)


def compute_accuracy(model, data_loader, device, margin=False):

    correct_pred, num_examples = 0, 0
    pred_total = []
    y_total = []
    gen_total = []

    for _, (_, features, targets, gender, _) in enumerate(data_loader):
        features = features.to(device).to(torch.float32)
        targets = targets.to(device)
        gender = gender.to(device)
        y = targets.cpu().detach().numpy()


        if margin:
            logits, _, _, _, _ = model(features, m=None, s=None)
        else:
            logits, _, _ = model(features)


        probas = torch.softmax(logits, dim=1)[:,1]  # margin/baseline ëª¨ë‘ 2ì°¨ì› [batch,2]ë¡œ ê°€ì •
        predicted_labels = (probas >= 0.5).int().squeeze()

        num_examples += targets.size(0)
        correct_pred += (predicted_labels == targets).sum()

        class_pred = predicted_labels.cpu().detach().numpy()
        gen = gender.cpu().detach().numpy()

        pred_total += class_pred.tolist()
        gen_total += gen.tolist()
        y_total += y.tolist()


    worst, avg = biased_acc(np.array(y_total), np.array(pred_total), np.array(gen_total))

    return correct_pred.float()/num_examples * 100, worst, avg